# -*- coding: utf-8 -*-
"""Predicting Restuarant Rating.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1qc-GDyyUHMPgRtOLONeWchlHEmGxqTtb
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler
from sklearn.impute import SimpleImputer
from sklearn.ensemble import RandomForestRegressor
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score

# Load the dataset
df = pd.read_csv("/content/Dataset .csv",encoding="ISO-8859-1")

# Display the first five rows
df.head()

df.replace({'\ufffd': ''}, regex=True, inplace=True)

df.fillna(df.mode().iloc[0], inplace=True)

print(df.head())

# Check for missing values
print(df.isnull().sum())

#dataset info
df.info()

label_encoders = {}
for col in ['Restaurant Name', 'City','Address','Locality','Locality Verbose','Cuisines','Currency','Has Table booking','Has Online delivery','Is delivering now','Switch to order menu','Rating color','Rating text']:
    le = LabelEncoder()
    df[col] = le.fit_transform(df[col])
    label_encoders[col] = le

# Use One-Hot Encoding for nominal categorical features
df = pd.get_dummies(df, columns=['Restaurant Name', 'City','Address','Locality','Locality Verbose','Cuisines','Currency','Has Table booking','Has Online delivery','Is delivering now','Switch to order menu','Rating color','Rating text'], drop_first=True)

# Define features (X) and target variable (y)
X = df.drop(columns=['Aggregate rating'])
y = df['Aggregate rating']

# Split the data into 80% training and 20% testing
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Train a Linear Regression model
lr_model = LinearRegression()
lr_model.fit(X_train, y_train)

# Train a Random Forest model
rf_model = RandomForestRegressor(n_estimators=100, random_state=42)
rf_model.fit(X_train, y_train)

# Predict on test data
y_pred_lr = lr_model.predict(X_test)
y_pred_rf = rf_model.predict(X_test)

# Evaluate Linear Regression Model
print("Linear Regression Performance:")
print(f"Mean Squared Error: {mean_squared_error(y_test, y_pred_lr)}")
print(f"R-squared: {r2_score(y_test, y_pred_lr)}")

# Evaluate Random Forest Model
print("\nRandom Forest Performance:")
print(f"Mean Squared Error: {mean_squared_error(y_test, y_pred_rf)}")
print(f"R-squared: {r2_score(y_test, y_pred_rf)}")

# Get feature importances from Random Forest
feature_importances = pd.Series(rf_model.feature_importances_, index=X.columns)
feature_importances.sort_values(ascending=False).plot(kind='bar', figsize=(10, 5))
plt.title("Feature Importance")
plt.show()

# Get feature importance from Random Forest
importances = pd.Series(rf_model.feature_importances_, index=X.columns)
importances.sort_values(ascending=False).plot(kind='bar', figsize=(10, 5), title="Feature Importance")